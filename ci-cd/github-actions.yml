name: DevStress Performance Test

on:
  pull_request:
    branches: [ main, develop ]
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      target_url:
        description: 'URL to test (defaults to staging)'
        required: false
      users:
        description: 'Number of concurrent users'
        required: false
        default: '100'

jobs:
  performance-test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install DevStress
      run: pip install devstress
      
    - name: Wait for deployment (if needed)
      run: sleep 30
      
    - name: Set target URL
      run: |
        if [ -n "${{ github.event.inputs.target_url }}" ]; then
          echo "TARGET_URL=${{ github.event.inputs.target_url }}" >> $GITHUB_ENV
        elif [ "${{ github.event_name }}" == "pull_request" ]; then
          echo "TARGET_URL=https://pr-${{ github.event.number }}-myapp.vercel.app" >> $GITHUB_ENV
        else
          echo "TARGET_URL=https://staging-myapp.vercel.app" >> $GITHUB_ENV
        fi
        
    - name: Run Performance Test
      id: devstress
      run: |
        devstress test ${{ env.TARGET_URL }} \
          --users ${{ github.event.inputs.users || '100' }} \
          --duration 30 \
          --scenario steady \
          --timeout 10 \
          --export json \
          --export md
      continue-on-error: true
      
    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-test-results
        path: |
          ~/.devstress/results/*.html
          ~/.devstress/results/*.json
          ~/.devstress/results/*.md
        retention-days: 30
        
    - name: Comment PR with Results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          try {
            // Read the latest test results
            const resultsDir = path.join(process.env.HOME, '.devstress/results');
            const files = fs.readdirSync(resultsDir).filter(f => f.endsWith('.md'));
            const latestFile = files.sort().reverse()[0];
            
            if (latestFile) {
              const reportPath = path.join(resultsDir, latestFile);
              const report = fs.readFileSync(reportPath, 'utf8');
              
              // Create comment body
              const comment = `
              ## ðŸš€ DevStress Performance Report
              
              **Target**: ${process.env.TARGET_URL}
              **Commit**: ${context.sha.substring(0, 7)}
              
              ${report}
              
              <details>
              <summary>View full results</summary>
              
              Check the **Actions** tab for detailed HTML reports and artifacts.
              
              </details>
              `;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }
          } catch (error) {
            console.log('Could not read test results:', error.message);
          }
          
    - name: Check Performance Thresholds
      run: |
        # This step fails the build if performance is unacceptable
        # DevStress CLI already returns appropriate exit codes
        exit ${{ steps.devstress.outcome == 'success' && '0' || '1' }}